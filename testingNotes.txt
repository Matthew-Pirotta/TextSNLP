- Reading the corpus was tested by reading a single file, and printing the first 2 sentences
- ngram was tested by performing 1,2,3 grams on the aforementioned second sentence
- tested ngram 1,2,3 on sample corpus


Total memory used by Corpus: 621.42 MB
Memory of ngrams (including elements): 120.30 MB
more efficient to remove total training data from corpus

counter_train_sentences = Counter(tuple(sentence) for sentence in train_sentences).most_common()

    total_memory_bytes = asizeof.asizeof(train_sentences)
    total_memory_mb = total_memory_bytes / (1024 * 1024)
    print(f"Total memory used by LIST Corpus: {total_memory_mb:.2f} MB")

    total_memory_bytes = asizeof.asizeof(counter_train_sentences)
    total_memory_mb = total_memory_bytes / (1024 * 1024)
    print(f"Total memory used by COUNTER Corpus: {total_memory_mb:.2f} MB")

Split corpus: 316950 training sentences, 79238 testing sentences
Total memory used by LIST Corpus: 496.66 MB
Total memory used by COUNTER Corpus: 489.41 MB

saving sentences in counter isnt more efficient which is expected