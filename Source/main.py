from pre_processing import *
from models import *

import sys
import os
import pandas as pd
import gc  # Import garbage collector
from pympler import asizeof
from collections import Counter

import cProfile, pstats

profile_dir = "./Stats"
models_path = "./Models"

def generate_perplexity_table(train_sentences, test_sentences) -> pd.DataFrame:
    columns = [ngram.name for ngram in NGramType]
    index = [model.value for model in LanguageModel]
    df = pd.DataFrame(index=index, columns=columns)

    for model_type in LanguageModel:
        model = Model(model_type)
        model.train(train_sentences)
        model.save_model(models_path)

        for ngram in NGramType:
            perplexity = model.calc_perplexity(test_sentences, ngram)
            df.at[model_type.value, ngram.name] = round(perplexity, 4)
        
        # Explicitly delete the model and run garbage collection
        del model
        gc.collect()
        
    return df

#NOTE User input was generated by AI
def user_select_model() -> LanguageModel:
    while True:
        print("Select a Language Model:")
        for i, model in enumerate(LanguageModel):
            print(f"{i + 1}. {model.value}")
        
        try:
            model_choice = int(input("Enter the number corresponding to your choice: ")) - 1
            if 0 <= model_choice < len(LanguageModel):
                selected_model = list(LanguageModel)[model_choice]
                print(f"Selected Language Model: {selected_model.value}")
                return selected_model
            else:
                print("Invalid choice. Please try again.")
        except ValueError:
            print("Invalid input. Please enter a number.")

def user_train_or_load() -> bool:
    while True:
        print("\nDo you want to train a new model or load an existing one?")
        print("1. Train a new model")
        print("2. Load an existing model")
        
        try:
            action_choice = int(input("Enter your choice (1 or 2): "))
            if action_choice == 1:
                return True 
            elif action_choice == 2:
                return False
            else:
                print("Invalid choice. Please enter 1 or 2.")
        except ValueError:
            print("Invalid input. Please enter a number (1 or 2).")

def user_sentence() -> str:
    print("Enter a phrase to generate a sentence:")
    start_sentence = input("Phrase: ")
    return start_sentence

def user_interaction():
    language_model = user_select_model()
    is_training = user_train_or_load()
    start_sentence = user_sentence()
    
    return language_model, is_training, start_sentence

def main_logic_without_user_input(language_model, is_training, start_sentence):
    model = Model(language_model) if is_training else Model.load(f"{models_path}/{language_model}")        
    
    corpus = PreProcessing.readSample()

    # Total memory of the Model instance (including all referenced objects)
    corpus_print_memory_usage(corpus)
    
    train_sentences, test_sentences = PreProcessing.train_test_split(corpus, train_ratio=.8)

    model.train(train_sentences)

    #model.print_memory_usage()
   
    generated_sentence = model.generate_sentence(start_sentence, NGramType.BIGRAM)
    print(f"start_sentence: {start_sentence}\nfull generated sentence: {generated_sentence}")
    df = generate_perplexity_table(train_sentences, test_sentences)
    print(df)

    # Save the DataFrame to a CSV file
    output_file = os.path.join(models_path, f"perplexity_table.csv")
    df.to_csv(output_file, index=True)
    print(f"Perplexity table saved to {output_file}")
    
    return df

def corpus_print_memory_usage(corpus):
    total_memory_bytes = asizeof.asizeof(corpus)
    total_memory_mb = total_memory_bytes / (1024 * 1024)
    print(f"Total memory used by Corpus: {total_memory_mb:.2f} MB")

def profileTime():
    os.makedirs(profile_dir, exist_ok=True)
    profile_file = os.path.join(profile_dir, "timeResults.cprof")
    time_sorted_file = os.path.join(profile_dir, "timeProfiling_sorted_by_time.txt")
    cumtime_sorted_file = os.path.join(profile_dir, "timeProfiling_sorted_by_cumtime.txt")
   
    language_model, is_training, start_sentence = user_interaction()
    
    with cProfile.Profile() as profile:
        main_logic_without_user_input(language_model, is_training, start_sentence)
        
    stats = pstats.Stats(profile)
    stats.dump_stats(profile_file)
   
    # Generate a file sorted by time
    with open(time_sorted_file, "w") as f:
        stats = pstats.Stats(profile_file, stream=f)
        stats.strip_dirs()  # Remove file path prefixes for better readability          
        stats.sort_stats(pstats.SortKey.TIME)
        stats.print_stats()
   
    # Generate a file sorted by cumulative time
    with open(cumtime_sorted_file, "w") as f:
        stats = pstats.Stats(profile_file, stream=f)
        stats.strip_dirs()  # Remove file path prefixes for better readability          
        stats.sort_stats(pstats.SortKey.CUMULATIVE)
        stats.print_stats()
   
    print(f"Profiling results saved to:\n- {time_sorted_file} (sorted by time)\n- {cumtime_sorted_file} (sorted by cumulative time)")

if __name__ == '__main__':
    profileTime()

    #Uncomment this and comment above to not profile time
    #language_model, is_training, start_sentence = user_interaction()
    #main_logic_without_user_input(language_model, is_training, start_sentence)

    print("done")